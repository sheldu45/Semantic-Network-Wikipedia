# Semantic-Network-Wikipedia
A multilingual basis to a semantic graph based on Wikipedia's data in 29 langages in order to create a semantical research engine. Work in progress! The outputs are CSV files which can be analysed either through Neo4j (noSQL) either through vocal requests which are treated by API.ai. Wikipedia dumps which are used are not cloned, they are the ones in a such format : "arwiki-20170820-pages-articles.xml" (for arabic). A version of "wikidata-sitelinks.nt" is necessary to figure out translation relationship amongst articles. This repo is an rudimentary. The initial idea was to extract hyperonomious relationship through wikipedia's infobox., in order to be able to solve questions asked to a bot (eg : "I am searching for a book about WW2" or "I am searching for a book written during WW2" etc...). At this time the code might not even work (but it has partially achieved it's goal at many points)
